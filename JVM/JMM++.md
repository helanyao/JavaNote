# <center>Deeply Understanding Memory Model</center>



## 1. 重排序

&#12288;&#12288;为了提高性能，编译器和处理器会对指令做重排序。重排序分三种类型：
1. 编译器优化重排序。编译器在不改变单线程程序语义前提下，重新安排语句的执行顺序。
2. 指令级并行重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。
3. 内存系统的排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。

&#12288;&#12288;从java源码到最终实际执行的指令序列，会经历下面三种重排序：

<p align="center">
  <img src="./Images/reording1.png" />
</p>

&#12288;&#12288;1属于编译器重排序，2和3属于处理器重排序。JMM编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。JMM的处理器重排序规则会要求java编译器在生成指令序列时，插入特定类型的内存屏障（memory barriers，intel称之为memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。

<br></br>


### 1.1 处理器重排序与内存屏障指令
<p align="center">
  <img src="./Images/reording2.png" />
</p>
<center><i>内存的读/写操作的执行示例</i></center>

<br>&#12288;&#12288;假设处理器A和处理器B按程序的顺序并行执行内存访问，最终却可能得到x = y = 0的结果。具体的原因如下图所示：

<p align="center">
  <img src="./Images/reording3.png" />
</p>

&#12288;&#12288;处理器A和B可以同时把共享变量写入自己的写缓冲区（A1，B1），然后从内存中读取另一个共享变量（A2，B2），最后才把自己写缓存区中的脏数据刷新到内存中（A3，B3）。当以这种时序执行时，程序得到x = y = 0的结果。由于写缓冲区仅对自己处理器可见，会导致处理器执行内存操作的顺序可能会与内存实际的操作执行顺序不一致。

&#12288;&#12288;现代的处理器都会允许对写-读操做重排序。处理器允许的重排序类型的列表：

| Type    |  Load-Load | Load-Store | Store-Store | Store-Load | 数据依赖 |
| :-----: | :-------:  | :--------: | :---------: | :------:   | :----:  |
| x86     | N          |  N         |   N         |  Y         |  N      |
| ia64    |   Y        |  Y         |    Y        |  Y         |   N     |
| PowerPC |    Y       |  Y         |    Y        |     Y      |   N     |

<center><i>“N”表示处理器不允许两个操作重排序，“Y”表示允许重排序。</i></center>

<br>&#12288;&#12288;JMM把内存屏障指令分为下列四类：

| 屏障类型    |             指令示例                 | 说明 | 
| :-------:  | :------------------------------:     | :-------- | 
| LoadLoad   | Load1; <br> LoadLoad; <br> Load2     | 确保Load1数据的装载，之前于Load2及所有后续装载指令的装载。  |   
| StoreStore | Store1; <br> StoreStore; <br> Store2 | 确保Store1数据对其他处理器可见（刷新到内存），之前于Store2及所有后续存储指令的存储。 |    
| LoadStore |  Load1; <br> LoadStore; <br> Store2 |  确保Load1数据装载，之前于Store2及所有后续的存储指令刷新到内存。 |   
| StoreLoad |  Store1; <br> StoreLoad; <br> Load2 |  确保Store1数据对其他处理器变得可见（刷新到内存），之前于Load2及所有后续装载指令的装载。 <br> StoreLoad Barriers使该屏障之前所有内存访问指令（存储和装载指令）完成后，才执行该屏障之后的内存访问指令。 |   

&#12288;&#12288;StoreLoad Barriers是一个“全能型”的屏障，它同时具有其他三个屏障的效果。现代的多处理器大都支持该屏障（其他类型的屏障不一定被所有处理器支持）。

<br></br>


### 1.2 数据依赖性
&#12288;&#12288;如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。数据依赖分三种类型：

| Item      |  Example | Comment  |
| :-------: | :------: |  :--: |
| 写后读     | a = 1;b = a; | 写一个变量之后，再读这个位置。 |
| 写后写     | a = 1;a = 2; | 写一个变量之后，再写这个变量。 |
| 读后写	    | a = b;b = 1; | 读一个变量之后，再写这个变量。 |

&#12288;&#12288;编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。注意，数据依赖性仅针对单处理器中执行的指令序列和单线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑

<br></br>


### 1.3 happens-before
&#12288;&#12288;重排序需要遵守happens-before规则:
* 程序次序法则，如果A一定在B之前发生，则happen before,
* 监视器法则,对一个监视器的解锁一定发生在后续对同一监视器加锁之前 
* volatie变量法则：写volatile变量一定发生在后续对它的读之前 
* 线程启动法则：Thread.start一定发生在线程中的动作 
* 中断法则：一个线程调用另一线程的interrupt一定发生在另一线程发现中断。
* 终结法则：一个对象的构造函数结束一定发生在对象的finalizer之前 
* 传递性：A发生在B之前，B发生在C之前，A一定发生在C之前。

&#12288;&#12288;注意，两个操作间具有happens-before关系，不意味着前一个操作要在后一个操作之前执行！happens-before仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）。

<p align="center">
  <img src="./Images/happens-before_JMM.png" />
</p>

<br></br>


### 1.4 重排序对多线程的影响

``` java
class ReorderExample {
	int a = 0;
	boolean flag = false;

	public void writer() {
    	a = 1;                   //1
    	flag = true;             //2
	}

	public void reader() {
    	if (flag) {                //3
        	int i =  a * a;        //4
    	}
	}
}
```

&#12288;&#12288;`flag`变量标识变量`a`是否已被写入。假设有两个线程A和B，A先执行`writer()`方法，随后B线程执行`reader()`方法。线程B在执行操作4时，能否看到线程A在操作1对共享变量`a`的写入？

&#12288;&#12288;答案是：不一定能看到。

&#12288;&#12288;由于操作1和操作2没有数据依赖关系，编译器和处理器可以对这两个操作重排序；同样，操作3和操作4没有数据依赖关系，编译器和处理器也可以对这两个操作重排序。操作1和操作2重排序时，会产生什么效果？请看下面的时序图：

<p align="center">
  <img src="./Images/reording_example1.png" />
</p>
<center><i>红色虚线表示错误的读操作，绿色虚线表示正确的读操作。</i></center>

<br>&#12288;&#12288;操作1和2做了重排序。线程A先写标记变量`flag`，随后线程B读这个变量。由于条件判断为真，线程B将读取变量`a`。此时，变量`a`还没有被线程A写入，在这里多线程程序的语义被重排序破坏了！

&#12288;&#12288;下面是操作3和操作4重排序后，程序的执行时序图：

<p align="center">
  <img src="./Images/reording_example2.png" />
</p>

<br>&#12288;&#12288;操作3和4存在控制依赖关系。当代码中存在控制依赖性时，会影响指令序列执行的并行度。为此，编译器和处理器会采用猜测（Speculation）执行来克服控制相关性对并行度的影响。执行线程B的处理器可以提前读取并计算`a * a`，然后把结果临时存到名为重排序缓冲（reorder buffer ROB）的硬件缓存中。当接下来操作3的条件判断为真时，就把计算结果写入变量`i`中。猜测执行实质上对操作3和4做了重排序。重排序在这里破坏了多线程程序的语义！

<br></br>



## 2. 数据竞争与顺序一致性保证

&#12288;&#12288;Java内存模型规范对数据竞争的定义如下：
* 在一个线程中写一个变量，
* 在另一个线程读同一个变量，
* 而且写和读没有通过同步来排序。

> JMM对正确同步的多线程程序的内存一致性做了如下保证：如果程序是正确同步的，程序的执行将具有顺序一致性（sequentially consistent）--即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同。

<br>


### 2.1 顺序一致性内存模型

&#12288;&#12288;顺序一致性内存模型有两大特性：
1. 一个线程中的所有操作必须按照程序的顺序来执行。

2.（不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见。

&#12288;&#12288;假设有线程A和B并发执行。A有三个操作，顺序是：A1->A2->A3。B顺序是：B1->B2->B3。这两个线程使用监视器来同步：A的三个操作执行后释放监视器，随后B获取监视器。在顺序一致性模型中的执行效果将如下图所示：

<p align="center">
  <img src="./Images/seq_consistent1.png" />
</p>

&#12288;&#12288;假设没有做同步，下面是未同步程序在顺序一致性模型中的执行示意图：

<p align="center">
  <img src="./Images/seq_consistent2.png" />
</p>

&#12288;&#12288;未同步程序在顺序一致性模型中虽然整体执行顺序是无序的，但所有线程都只能看到一个一致的整体执行顺序。A和B看到的执行顺序都是：B1->A1->A2->B2->A3->B3。之所以能得到这个保证是因为顺序一致性内存模型中的每个操作必须立即对任意线程可见。

&#12288;&#12288;但在JMM中就没有这个保证。未同步程序在JMM中不但整体的执行顺序是无序的，而且所有线程看到的操作执行顺序也可能不一致。比如，在当前线程把写过的数据缓存在本地内存中，且还没有刷新到主内存之前，这个写操作仅对当前线程可见。在这种情况下，当前线程和其它线程看到的操作执行顺序将不一致。

<br>


### 2.2 同步程序的执行特性

``` java
class SynchronizedExample {
	int a = 0;
	boolean flag = false;

	public synchronized void writer() {
    	a = 1;
    	flag = true;
	}

	public synchronized void reader() {
    	if (flag) {
        	int i = a;
    	}
	}
}
```

&#12288;&#12288;该程序在两个内存模型中的执行时序对比图：

<p align="center">
  <img src="./Images/seq_consistent3.png" />
</p>

&#12288;&#12288;在顺序一致性模型中，所有操作完全按程序的顺序串行执行。在JMM中，临界区内代码可以重排序（JMM不允许临界区内的代码“逸出”到临界区之外）。JMM在退出监视器和进入监视器这两个时间点做一些处理，使线程在这两个时间点具有与顺序一致性模型相同的内存视图。虽然A在临界区内做了重排序，但由于监视器互斥执行的特性，B无法“观察”到A在临界区内的重排序。

<br>


### 2.3 未同步程序的执行特性
&#12288;&#12288;对未同步多线程程序，JMM只提供最小安全性：线程执行时读取的值，要么是之前某个线程写入的值，要么是默认值（0，`null`，`false`），JMM保证线程读操作读取到的值不会无中生有（out of thin air）的冒出来。为实现最小安全性，JVM在堆上分配对象时，先会清零内存空间，然后在上面分配对象（JVM内部会同步这两个操作）。因此，在以清零的内存空间（pre-zeroed memory）分配对象时，域的默认初始化已经完成了。

&#12288;&#12288;和顺序一致性模型一样，未同步程序在JMM中的执行时，整体上也是无序的。未同步程序在两个模型中的执行特性有下面几个差异：

1. 顺序一致性模型保证单线程内的操作会按程序的顺序执行，而JMM不保证。
2. 顺序一致性模型保证所有线程只能看到一致的执行顺序，而JMM不保证。
3. JMM不保证对64位的`long`/`double`型变量的读写操作具有原子性，而顺序一致性模型保证对所有的内存读写操作都具有原子性。

&#12288;&#12288;第3个差异与处理器总线的工作机制相关。数据通过总线在处理器和内存间传递。每次处理器和内存间的数据传递是通过一系列步骤来完成的，称为总线事务（bus transaction）。包括读事务（read transaction）和写事务（write transaction）。读事务从内存传送数据到处理器，写事务从处理器传送数据到内存。这里的关键是，总线会同步试图并发使用总线的事务。在处理器执行总线事务期间，总线会禁止其它处理器和I/O设备执行内存读/写。

&#12288;&#12288;一些32位的处理器上，如要对64位数据的读/写操作具有原子性，会有较大的开销。为了照顾这种处理器，java不强求JVM对64位的`long`/`double`型变量的读写具有原子性。当JVM在这种处理器上运行时，会把一个64位`long`/`double`型变量的读写操作拆分为两个32位的读写操作来执行。这两个32位的读/写操作可能会被分配到不同的总线事务中执行，此时对这个64位变量的读写将不具有原子性：

<p align="center">
  <img src="./Images/32_64.png" />
</p>

<br></br>



## 3. Conclusion
### 3.1 内存屏障
&#12288;&#12288;由于常见的处理器内存模型比JMM要弱，java编译器在生成字节码时，会在执行指令序列的适当位置插入内存屏障来限制处理器的重排序。同时，由于各种处理器内存模型的强弱并不相同，为了在不同的处理器平台向程序员展示一个一致的内存模型，JMM在不同的处理器中需要插入的内存屏障的数量和种类也不相同。

<p align="center">
  <img src="./Images/conclusion1.png"/>
</p>
<center><i>JMM在不同处理器内存模型中需要插入的内存屏障</i></center>

<br>


### 3.2 JMM，处理器内存模型与顺序一致性内存模型之间的关系
&#12288;&#12288;JMM是一个语言级的内存模型，处理器内存模型是硬件级的内存模型，顺序一致性内存模型是一个理论参考模型。下面是语言内存模型，处理器内存模型和顺序一致性内存模型的强弱对比示意图：

<p align="center">
  <img src="./Images/conclusion2.png"/>
</p>

<br>


### 3.3 JMM设计

&#12288;&#12288;在设计JMM时，需考虑两个关键因素：

1. 程序员对内存模型的使用。程序员希望内存模型易于理解，易于编程。程序员希望基于一个强内存模型来编写代码。
2. 编译器和处理器对内存模型的实现。编译器和处理器希望内存模型对它们的束缚越少越好，这样它们就可以做尽可能多的优化来提高性能。编译器和处理器希望实现一个弱内存模型。

&#12288;&#12288;下面让看看如何实现这一目标。

``` java
double pi  = 3.14;    //A
double r   = 1.0;     //B
double area = pi * r * r; //C
```

&#12288;&#12288;happens- before关系：
1. A happens- before B
2. B happens- before C
3. A happens- before C

&#12288;&#12288;由于A happens-before B，happens-before的定义要求：A操作执行的结果要对B可见，且A操作的执行顺序排在B操作之前。但从程序语义角度来说，对A和B做重排序不会改变执行结果，还能提高性能（允许这种重排序减少了对编译器和处理器优化的束缚）。也就是说，虽然2和3是必需要的，但1是不必要的。

&#12288;&#12288;因此，JMM把happens-before要求禁止的重排序分为了下面两类：
1. 会改变程序执行结果的重排序。
2. 不会改变程序执行结果的重排序。

&#12288;&#12288;JMM对这两种重排序采取了不同的策略：
1. 对于会改变程序执行结果的重排序，JMM要求编译器和处理器必须禁止这种重排序。
2. 对于不会改变程序执行结果的重排序，JMM对编译器和处理器不作要求（JMM允许这种重排序）。

<p align="center">
  <img src="./Images/conclusion3.png"/>
</p>
<center><i>JMM设计示意图</i></center>

<br>&#12288;&#12288;从上图可以看出两点：
1. JMM提供的happens-before规则能满足程序员的需求。不但简单易懂，也向程序员提供了足够强的内存可见性保证。
2. JMM对编译器和处理器的束缚已尽可能的少。JMM遵循一个基本原则：只要不改变程序的执行结果（指的是单线程程序和正确同步的多线程程序），编译器和处理器怎么优化都行。比如，如果编译器经过分析后，认定一个锁只会被单个线程访问，那么这个锁可以被消除。再比如，如果编译器经过分析后，认定volatile变量只被单个线程访问，那么编译器可以把volatile变量当作普通变量对待。这些优化既不会改变程序的执行结果，又能提高程序的执行效率。

<br>


### 3.4 内存可见性保证

&#12288;&#12288;Java程序的内存可见性保证分为三类：

1. 单线程程序。单线程程序不会出现内存可见性问题。编译器，runtime和处理器会共同确保单线程程序的执行结果与该程序在顺序一致性模型中的执行结果相同。
2. 正确同步的多线程程序。正确同步的多线程程序的执行将具有顺序一致性（程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同）。JMM通过限制编译器和处理器的重排序来为程序员提供内存可见性保证。
3. 未同步/未正确同步的多线程程序。JMM为它们提供了最小安全性保障：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值（0，`null`，`false`）。

<p align="center">
  <img src="./Images/conclusion3.png"/>
</p>
<center><i>三类程序在JMM中与在顺序一致性内存模型中的执行结果</i></center>

<br>&#12288;&#12288;只要多线程程序是正确同步的，JMM保证该程序在任意的处理器平台上的执行结果，与该程序在顺序一致性内存模型中的执行结果一致。





